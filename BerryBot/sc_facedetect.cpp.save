//COMMAND LINE :

//g++-6 sc_facedetect.cpp -lopencv_core -lopencv_imgproc -lopencv_objdetect -lopencv_highgui -lopencv_imgcodecs -lopencv_videoio -std=c++17 -lpthread -lwiringPi -o a.out

//g++ sc_facedetect.cpp -lopencv_core -lopencv_imgproc -lopencv_objdetect -lopencv_highgui -lopencv_imgcodecs -lopencv_videoio -std=c++17 -lpthread  -o a.out -I ../opencv/modules/objdetect/include/ -I ../opencv/modules/core/include/ -I ../opencv/build/ -I ../opencv/modules/highgui/include/ -I ../opencv/modules/imgcodecs/include/ -I ../opencv/modules/videoio/include/ -I ../opencv/modules/imgproc/include/


#define BOARD RASPBERRY_PI


#include <errno.h>
#include <wiringPiI2C.h>

#include <thread>
#include <chrono>
#include <mutex>
#include <iostream>
#include <stdlib.h>
#include <set>
#include <queue>
#include <functional>
#include <memory>
#include <string>

#include "opencv2/videoio.hpp"
#include "opencv2/objdetect.hpp"
#include "opencv2/highgui.hpp"
#include "opencv2/imgproc.hpp"
#include <iostream>
#include <fstream>
#include <unistd.h>
#include <fcntl.h>
#include <termios.h>

#include <linux/i2c-dev.h>

#include "sc_facedetect.hpp"
#include "sc_common.hpp"

#define FRAME_WIDTH 320
#define FRAME_HEIGHT 240
#define FRAME_RATE 1

#define RADIUS_REFERENCE 30

using namespace std;
using namespace cv;
using namespace USB_COMM;


#define USER_ENABLED true

#define NUM_OF_REC_POS 8
vector<pair<int,int>> vpos( NUM_OF_REC_POS, pair<int,int>(0,0) );
int lastPopulatedIndex = -1;

static void help()
{
    cout << "\nThis program demonstrates the cascade recognizer. Now you can use Haar or LBP features.\n"
            "This classifier can recognize many kinds of rigid objects, once the appropriate classifier is trained.\n"
            "It's most known use is for faces.\n"
            "Usage:\n"
            "./facedetect [--cascade=<cascade_path> this is the primary trained classifier such as frontal face]\n"
               "   [--nested-cascade[=nested_cascade_path this an optional secondary classifier such as eyes]]\n"
               "   [--scale=<image scale greater or equal to 1, try 1.3 for example>]\n"
               "   [--try-flip]\n"
               "   [filename|camera_index]\n\n"
            "see facedetect.cmd for one call:\n"
            "./facedetect --cascade=\"../../data/haarcascades/haarcascade_frontalface_alt.xml\" --nested-cascade=\"../../data/haarcascades/haarcascade_eye_tree_eyeglasses.xml\" --scale=1.3\n\n"
            "During execution:\n\tHit any key to quit.\n"
            "\tUsing OpenCV version " << CV_VERSION << "\n" << endl;
}


bool detectAndDraw( Mat& img, CascadeClassifier& cascade, CascadeClassifier& nestedCascade, double scale, bool tryflip,
                                        int& xError, int& zError );
                    
void configI2C();
int configSerial();



//PID processing
void processPositionData()
{   
    static int sumX = 0;
    static int sumZ = 0;
    
    //Integrate the last n positions for error on x
    sumX += vpos[lastPopulatedIndex].first - vpos[(lastPopulatedIndex+1) % NUM_OF_REC_POS ].first;
    
     //Integrate the last n positions for error on z
    sumZ += vpos[lastPopulatedIndex].second - vpos[(lastPopulatedIndex+1) % NUM_OF_REC_POS ].second;
}

void userInput(mutex& mMatCapt, std::queue<Mat>& cuQ)
{
          int c = 0;
          int  i = 0;

          while(1)
          {
                //pop image clone sent from detection task
                mMatCapt.lock();
                
                if (!cuQ.empty())
                {
                    //cout << "\n\r got frame to display" << endl;
                    imshow( "result", cuQ.front( ));
                    cuQ.pop();  
                }
                
                 mMatCapt.unlock();
                 
                 c = waitKey(1);
                             
                std::this_thread::yield();
          }
}


#define START_MSG_BYTE 0x7B
#define END_MSG_BYTE     0x7D
#define ESCAPE_BYTE         0x7E
#define UNESCAPE_BYTE(x) (0xFF & (0x20 ^ (x)))

void communicateMoves( mutex& mCommCapt, std::queue<CommCaptMsg>& ccQ, int serComHdl )
{
        //cout << "Entered detectFaces Thread" ;
        //----- TX BYTES -----
	   
	    char tx_buffer[50];
	    char rx_buffer[32];
	    unsigned char *p_tx_buffer;
	    struct CommCaptMsg msg; 
	   
	   
	    //cout << "start message " << message ;
	
        while(1)
        {
                 mCommCapt.lock();
                 if (!ccQ.empty())
                 {
                          msg = ccQ.front();
                           
                           string message("{ ");
                          //check if we need urgent stop
                         // if (msg.zError >0)
                         // {
                          ///    message+="STOP";
                          //}
                         // else 
                         //{
	                            message+="CHANGE ";
                       
                                message += to_string(msg.xError);

                                message += " ";
                                message += to_string(msg.zError);
	                      // }
	                       // message += " ";
	                        message += " }";
	                        
	                       
	                       cout << message << endl;
	   
                           //for (int i = 0; i < 100; ++i)
                           //{
                                
                                //int count = write(serComHdl, &tx_buffer[0],  1);	
                                //serial_port_write(tx_buffer, 9);
                               int count =  write(serComHdl, message.c_str(), message.size());
                                
                                //int readLen = serial_port_read(rx_buffer, MAX_COMMAND_LENGTH);
                                
                                //if (readLen > 0)
                                //{
                                //    string buffStr(rx_buffer, readLen);
                                //    cout <<"\n\r Got response from robot " << buffStr;
                                //}
			                  
		                    ccQ.pop();  
                           //cout << "\n\r communicateMoves Poped index " << msg.key;
                 }
                mCommCapt.unlock();
                
                 std::this_thread::yield();
                 //this_thread::sleep_for(chrono::milliseconds(30));

        }
}



void detectFaces(VideoCapture capture, CascadeClassifier cascade, CascadeClassifier nestedCascade, double scale, bool tryflip, 
                                std::mutex& mCommCapt, std::queue<CommCaptMsg>& ccQ, 
                                std::mutex&  mMatCapt, std::queue<Mat>& cuQ) 
{

    bool motionDetected = false;
	int frameIndex = 0;
    Mat frame, frame1;
    struct CommCaptMsg msg;
    int xError = 0;
    int zError = 0;

    cout << "Entered detectFaces Thread" ;
    //system("xterm -T "t1" ");
    while(1)
    {
	          //cout << "Thread running ..." ;
	          //this_thread::sleep_for(chrono::milliseconds(30));
            
            capture >> frame;
            if( frame.empty() )
            {
                    cout << "Frame is empty, quitting!";
                    continue;
            }
            //frame1 = frame.clone();
            motionDetected = detectAndDraw( frame, cascade, nestedCascade, scale, false, xError, zError );
            
           if (motionDetected == true)
           {
	            msg.key = ++frameIndex;
	            msg.xError = xError ;
	            msg.zError = zError ;
	            
	            printf("\n\r msg.xError = %d msg.zError = %d", msg.xError, msg.zError);
	            
	            //push message for Comm task
	            mCommCapt.lock();
                ccQ.push(msg);
                mCommCapt.unlock();
           }
            
            #if USER_ENABLED == true
            //push image clone for user Task
            mMatCapt.lock();
            cuQ.push(frame.clone());
            mMatCapt.unlock();
            #endif
               
	        std::this_thread::yield();
            
    }

}




int main( int argc, const char** argv )
{

        int serialCommHdl = configSerial();
        
        std::mutex m1;
        std::mutex m2;
        //we need a queue between comm and capture
        std::queue<CommCaptMsg> captComQ; 
        //we need a queue between capture and userInput 
        std::queue<Mat> captUserQ; 
        
        VideoCapture capture;
        Mat image;
        string inputName;
        bool tryflip;
        CascadeClassifier cascade, nestedCascade;
        double scale;
        string cascadeName;
        string nestedCascadeName;

        cv::CommandLineParser parser(argc, argv,
                                                                "{help h||}"
                                                                "{cascade|../../data/haarcascades/haarcascade_frontalface_alt.xml|}"
                                                                //"{nested-cascade|../../data/haarcascades/haarcascade_eye_tree_eyeglasses.xml|}"
                                                                "{nested-cascade|../../data/haarcascades/cars.xml|}"
                                                                "{scale|1|}{try-flip||}{@filename||}"
                                                                );
        
        if (parser.has("help"))
        {
                help();
                return 0;
        }
        cascadeName = parser.get<string>("cascade");
        nestedCascadeName = parser.get<string>("nested-cascade");
        scale = parser.get<double>("scale");
        if (scale < 1)
                scale = 1;
        tryflip = parser.has("try-flip");
        inputName = parser.get<string>("@filename");
        if (!parser.check())
        {
                parser.printErrors();
                return 0;
        }
        if ( !nestedCascade.load( nestedCascadeName ) )
                cerr << "WARNING: Could not load classifier cascade for nested objects" << endl;
                
        if( !cascade.load( cascadeName ) )
        {
                cerr << "ERROR: Could not load classifier cascade" << endl;
                help();
                return -1;
        }
        if( inputName.empty() || (isdigit(inputName[0]) && inputName.size() == 1) )
        {
                int c = inputName.empty() ? 0 : inputName[0] - '0';
                if(!capture.open(c))
                        cout << "Capture from camera #" <<  c << " didn't work" << endl;
        }
        else if( inputName.size() )
        {
                    image = imread( inputName, 1 );
                    if( image.empty() )
                    {
                            if(!capture.open( inputName ))
                                cout << "Could not read " << inputName << endl;
                    }
                    }
                    else
                    {
                            image = imread( "../data/lena.jpg", 1 );
                            if(image.empty()) cout << "Couldn't read ../data/lena.jpg" << endl;
                    }

        capture.set(CAP_PROP_FRAME_WIDTH, FRAME_WIDTH);
        capture.set(CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT);
        capture.set(CAP_PROP_FPS, FRAME_RATE);

        if( capture.isOpened() )
        {
                cout << "Video capturing has been started ..." << endl;

                //we keep threads ID in the set
                std::set<std::thread::id>  ts;
                
                #if USER_ENABLED == true
                std::thread userThread(userInput,  std::ref(m2), std::ref(captUserQ)  );
                std::thread::id ut1 = userThread.get_id();
                ts.insert(ut1);
                cout <<"\n\r Started Thread to get input from user id=" << ut1;
                userThread.detach();
                #endif
                
                //start a thread for detection
                std::thread detectThread( detectFaces, capture, cascade, nestedCascade, scale, tryflip, std::ref(m1), std::ref(captComQ ) , std::ref(m2), std::ref(captUserQ) ); 
                std::thread::id dt1 = detectThread.get_id();
                ts.insert(dt1);
                cout << "\n\r Started Thread to detect faces id=" << dt1;
                detectThread.detach();

                //start a thread for communication of the moves
                
                std::thread commThread(communicateMoves, std::ref(m1), std::ref(captComQ ) , serialCommHdl);	
                std::thread::id ct1 = commThread.get_id();
                ts.insert(ct1);
                cout <<"\n\r Started Thread to communicate moves id=" << ct1;
                commThread.detach();
                
            
                while(1)
                {
                /*
                     int c = waitKey(30);
                     if( c == 27 || c == 'q' || c == 'Q' )
                     {
                         cout << "\n\r Detected quit key, quitting!";
	                        break;
                     }
                     */
                    

                }
        }
        else
        {
                cout << "Video capturing cannot be started, not opened ..." << endl;
                   
        }

        return 0;
}


vector<Rect> faces, faces2;
const static Scalar colors[] =
 {
                Scalar(255,0,0),
                Scalar(255,128,0),
                Scalar(255,255,0),
                Scalar(0,255,0),
                Scalar(0,128,255),
                Scalar(0,255,255),
                Scalar(0,0,255),
                Scalar(255,0,255)
 };
    
bool detectAndDraw( Mat& img, CascadeClassifier& cascade, CascadeClassifier& nestedCascade, double scale, bool tryflip,
                                      int& xError, int& zError )
{
    //TZ
    bool motionDetected = false;
    static Point centerPrev;
    static int radiusPrev = 0;
    
    double t = 0;
    
    Mat gray, smallImg;

    cvtColor( img, gray, COLOR_BGR2GRAY );
    double fx = 1 / scale;
    resize( gray, smallImg, Size(), fx, fx, INTER_LINEAR );
    equalizeHist( smallImg, smallImg );

    t = (double)cvGetTickCount();
    cascade.detectMultiScale( smallImg, faces,
                                                    1.1, 2, 0
                                                    //|CASCADE_FIND_BIGGEST_OBJECT
                                                    //|CASCADE_DO_ROUGH_SEARCH
                                                    |CASCADE_SCALE_IMAGE,
                                                    Size(30, 30) );
    if( tryflip )
    {
            flip(smallImg, smallImg, 1);
            cascade.detectMultiScale( smallImg, faces2,
                                                         1.1, 2, 0
                                                         //|CASCADE_FIND_BIGGEST_OBJECT
                                                         //|CASCADE_DO_ROUGH_SEARCH
                                                         |CASCADE_SCALE_IMAGE,
                                                         Size(30, 30) );
            for( vector<Rect>::const_iterator r = faces2.begin(); r != faces2.end(); r++ )
            {
                faces.push_back(Rect(smallImg.cols - r->x - r->width, r->y, r->width, r->height));
            }
    }
    t = (double)cvGetTickCount() - t;
    //printf( "detection time = %g ms  faces.size()=%d\n", t/((double)cvGetTickFrequency()*1000.), faces.size() );
    for ( size_t i = 0; i < faces.size(); i++ )
    {
        Rect r = faces[i];
        Mat smallImgROI;
        vector<Rect> nestedObjects;
        Point center;
        Scalar color = colors[i%8];
        int radius;

        double aspect_ratio = (double)r.width/r.height;
        if( 0.75 < aspect_ratio && aspect_ratio < 1.3 )
        {
            center.x = cvRound((r.x + r.width*0.5)*scale);
            center.y = cvRound((r.y + r.height*0.5)*scale);
            
             if (center.x  != centerPrev.x)
            {
                motionDetected = true;
                //deviation from center in %
                xError =  static_cast<int>(100 * (center.x  - FRAME_WIDTH/2) /  (FRAME_WIDTH/2)); 
                printf("  Moved Horizintal by= %d pc", xError);
                centerPrev = center;
            }
            
            radius = cvRound((r.width + r.height)*0.25*scale);
            circle( img, center, radius, color, 3, 8, 0 );
           
            if (radius != radiusPrev)
            {
                motionDetected = true;
                if (radiusPrev != 0)
                {
                    zError =  static_cast<int>( 100 * (radius - radiusPrev) / radiusPrev);
                }
                radiusPrev = radius;
                printf("  changed radius by= %d pc", zError);
            }
         
            //populate the positions vector
            lastPopulatedIndex =  (++lastPopulatedIndex) % NUM_OF_REC_POS;
            vpos[lastPopulatedIndex] = pair<int,int>(xError, zError);
            
        }
        else
        {
            rectangle( img, cvPoint(cvRound(r.x*scale), cvRound(r.y*scale)),
                       cvPoint(cvRound((r.x + r.width-1)*scale), cvRound((r.y + r.height-1)*scale)),
                       color, 3, 8, 0);
        }
        
        #ifdef PROCESS_NESTED
        if( nestedCascade.empty() )
        {
            continue;
        }
        #else
        continue;
        #endif
        smallImgROI = smallImg( r );
        
        nestedCascade.detectMultiScale( smallImgROI, nestedObjects,
                                                                    1.1, 2, 0
                                                                    //|CASCADE_FIND_BIGGEST_OBJECT
                                                                    //|CASCADE_DO_ROUGH_SEARCH
                                                                    //|CASCADE_DO_CANNY_PRUNING
                                                                    |CASCADE_SCALE_IMAGE,
                                                                    Size(30, 30) );
                                                                    
        for ( size_t j = 0; j < nestedObjects.size(); j++ )
        {
                Rect nr = nestedObjects[j];
                center.x = cvRound((r.x + nr.x + nr.width*0.5)*scale);
                center.y = cvRound((r.y + nr.y + nr.height*0.5)*scale);
                radius = cvRound((nr.width + nr.height)*0.25*scale);
                circle( img, center, radius, color, 3, 8, 0 );
        }
    }
   // imshow( "result", img );
   
   return motionDetected;
}



int configSerial()
{
        USB_COMM::serial_port_open();
        
        /*
         int uart0_filestream = -1;
        //uart0_filestream = open("/dev/ttyS0", O_RDWR | O_NOCTTY | O_NDELAY);
        
        uart0_filestream = open("/dev/ttyS0", O_RDWR);
        
        if (uart0_filestream == -1)
        {
                printf("\n\r Could not open UART stream");
        }
        else
        {
                printf("\n\r UART stream opened successfully!");
        }
        
        struct termios options;
	    tcgetattr(uart0_filestream, &options);
	    options.c_cflag = B9600 | CS8 | CLOCAL | CREAD;		//<Set baud rate
	    options.c_iflag = IGNPAR;
	    options.c_oflag = 0;
	    options.c_lflag = 0;
	    tcflush(uart0_filestream, TCIFLUSH);
	    tcsetattr(uart0_filestream, TCSANOW, &options);
	    
	    return uart0_filestream;
	    */
}



void configI2C()
{
/*
    int result;
    int fd = wiringPiI2CSetup(0x40);
    
    cout << "I2C Setup Init result: "<< fd << endl;
    
    
    /*
       for(int i = 0; i < 0x0000ffff; i++)
       {
          result = wiringPiI2CWriteReg16(fd, 0x40, (i & 0xfff) );

          if(result == -1)
          {
             //cout << "Error.  Errno is: " << errno << endl;
          }
          else
          {
             //cout << "I2C success!!: " << result << endl;
          }
       }
       */
       
       
}



